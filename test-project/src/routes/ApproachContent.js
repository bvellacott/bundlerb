import { h, Fragment } from 'preact'
import { InlineImage } from '@/components/InlineImage'

export const ApproachContent = () => (
	<>
    <p>
      <InlineImage src="/bundlerb_mirror.gif" />The approach in this project assumes that the developer is careful in picking dependencies into
      a project.<InlineImage src="/bundlerb.gif" /> This would mean that a new dependency is rarely added and when so, it's size would
      be as small as possible. This assumption gives way to the possibility of the build tool to handle
      the bundling of the dependencies as well as the native code. <InlineImage src="/bundlerb_mirror.gif" />That is what this project does and
      instead of defining entry files for whatever bundle you are building at any given time, you start
      a server and request the entry file that you wish to receive as a bundle.<InlineImage src="/bundlerb.gif" /> The first question that
      I assume that you are asking is: "Isn't that slow?". And I would answer, I don't believe so, if the
      problem is solved properly.
    </p>
    <h3><InlineImage src="/bundlerb_mirror.gif" /> Babel and Webpack overlap</h3>
    <p>
      In a standard Webpack build, Webpack is the one resolving dependencies and creating the bundle.
      However Babel is used for doing all the transformations and potentially linting. This means that
      the code is being parsed twice every time you build.
    </p>
    <h3>Expensive operations should run only on the files that changed</h3>
    <p>
      This is the problem Broccoli tried to (and did for the most part) solve in a manageable way with it's tree cache setup.
      The problem with Broccoli is though that each plugin is reading the filesystem. This is not so much a problem with modern
      disks, but more a problem with the fact that the cache is always a file rather than a js object. So every time a plugin
      runs, even on cached content, the file and and most likely the related files need to parsed.
      BundlerB<InlineImage src="/bundlerb.gif" /> simply keeps a cache of each trasformed file as an AST (Abstract Syntax Tree)
      and a string result. That means every subsequent step in the transformation doesn't need to parse and write to disk and
      also that when a file changes, the transformations are run on that file only and finally a string concatenation is returned
      of all the files needed.
    </p>
    <h3>Babel and Postcss drive the build</h3>
    <p>
      The philosophy in BundlerB<InlineImage src="/bundlerb.gif" /> is to use Babel and Postcss as the drivers for the build.
      If a plugin is needed, you should try and solve it as a babel and/or postcss problem and write a babel and/or postcss plugin.
      For instance, resolving dependencies and support for cjs modules is done using babel plugins. Now, if for instance tree shaking
      were needed, a babel plugin would be the obvious way to go. Webpack for instance handles tree shaking in a separate process to
      the bable transformation.
    </p>
    <h3>Dependency overlap and entry files</h3>
    <p>
      In webpack, and I think, every other build tool, entry files for each bundle need to be defined. It's not a massive piece of
      work in itself, but when code splitting and snippets come into play, this can become laborious. I've seen a nice setup where
      the Webpack entry files are autogenerated to a configurable granularity. The best setup with that seemed to be to set it
      to as granular as possible and then use http2 to serve the files, because when code splitting, code often gets loaded several
      times due to overlap in dependencies. Now that is a !REALLY! interesting point if you're tired of the complexity of build tools,
      because it's exactly the same as using require.js over http2, which in my view is a very viable option.
      BundlerB<InlineImage src="/bundlerb.gif" /> on the other hand operates as a service and it will accept id's of files that 
      the client has received in a previous request and only bundle files that the client doesn't yet have. There is a small client 
      side script called <InlineImage src="/bundlerb_mirror.gif" /><strong>bequire.js</strong> which handles this automatically when doing
      dynamic requires.
    </p>
    <h3>Server Side Rendering</h3>
    <p>
      As previously mentioned, Razzle does a good job of simplyfying ssr setups. But razzle has a very separate server side build
      from the client side build, and again single file changes take several seconds to build on a large project. With
      <InlineImage src="/bundlerb_mirror.gif" />BundlerB a single file change costs a single file transformation and a concatenation on
      the client and the server together. No browsersync or websocket setup is added to automatically refresh the browser when
      a file changes, because that doesn't fit with the loading mechanism. BundlerB<InlineImage src="/bundlerb.gif" /> checks,
      the file timestamps, content length and content (in that order), on each request, to see if a file has changed and therefore
      no unreliable file watching is needed for the client side build, although for the server side it's still needed.
    </p>
    <h3>Serving static assets</h3>
    <p>
      If you have heard of Gatsby, you know that it's a nice tool to create a static website. The problem with it though, is that
      it uses Webpack and forces you to use React. And again you have to work with entries and oppinionated setups where the only way
      forward is a hack etc... With <InlineImage src="/bundlerb_mirror.gif" />BundlerB, because it operates as a service, you can
      generate your static site just by asking for the files that you need. This project includes the build script to do just that.
    </p>
	</>
)

